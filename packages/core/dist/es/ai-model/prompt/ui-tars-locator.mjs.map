{"version":3,"file":"ai-model\\prompt\\ui-tars-locator.mjs","sources":["webpack://@sqaitech/core/./src/ai-model/prompt/ui-tars-locator.ts"],"sourcesContent":["import { getPreferredLanguage } from '@sqaitech/shared/env';\r\n\r\n// claude 3.5 sonnet computer The ability to understand the content of the image is better, Does not provide element snapshot effect\r\nexport function systemPromptToLocateElementPosition() {\r\n  const preferredLanguage = getPreferredLanguage();\r\n\r\n  return `\r\nYou are a GUI agent. You are given a task and your action history, with screenshots. You need to perform the next action to complete the task. \r\n\r\n## Output Format\r\n\\`\\`\\`\r\nThought: ...\r\nAction: ...\r\n\\`\\`\\`\r\n\r\n## Action Space\r\nclick(start_box='[x1, y1, x2, y2]')\r\nleft_double(start_box='[x1, y1, x2, y2]')\r\nright_single(start_box='[x1, y1, x2, y2]')\r\ndrag(start_box='[x1, y1, x2, y2]', end_box='[x3, y3, x4, y4]')\r\nhotkey(key='')\r\ntype(content='') #If you want to submit your input, use \"\\\\n\" at the end of \\`content\\`.\r\nscroll(start_box='[x1, y1, x2, y2]', direction='down or up or right or left')\r\nwait() #Sleep for 5s and take a screenshot to check for any changes.\r\nfinished()\r\ncall_user() # Submit the task and call the user when the task is unsolvable, or when you need the user's help.\r\n\r\n## Note\r\n- Use ${preferredLanguage} in \\`Thought\\` part.\r\n- Write a small plan and finally summarize your next action (with its target element) in one sentence in \\`Thought\\` part.\r\n\r\n## User Instruction\r\n    `;\r\n}\r\n"],"names":["systemPromptToLocateElementPosition","preferredLanguage","getPreferredLanguage"],"mappings":";AAGO,SAASA;IACd,MAAMC,oBAAoBC;IAE1B,OAAO,CAAC;;;;;;;;;;;;;;;;;;;;;;MAsBJ,EAAED,kBAAkB;;;;IAItB,CAAC;AACL"}