{"version":3,"file":"ai-model\\llm-planning.js","sources":["webpack://@sqai/core/webpack/runtime/define_property_getters","webpack://@sqai/core/webpack/runtime/has_own_property","webpack://@sqai/core/webpack/runtime/make_namespace_object","webpack://@sqai/core/./src/ai-model/llm-planning.ts"],"sourcesContent":["__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n        if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n            Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n        }\n    }\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","import type {\r\n  DeviceAction,\r\n  InterfaceType,\r\n  PlanningAIResponse,\r\n  UIContext,\r\n} from '@/types';\r\nimport type { IModelConfig } from '@sqai/shared/env';\r\nimport { paddingToMatchBlockByBase64 } from '@sqai/shared/img';\r\nimport { getDebug } from '@sqai/shared/logger';\r\nimport { assert } from '@sqai/shared/utils';\r\nimport type {\r\n  ChatCompletionContentPart,\r\n  ChatCompletionMessageParam,\r\n} from 'openai/resources/index';\r\nimport {\r\n  AIActionType,\r\n  buildYamlFlowFromPlans,\r\n  fillBboxParam,\r\n  findAllMidsceneLocatorField,\r\n  markupImageForLLM,\r\n  warnGPT4oSizeLimit,\r\n} from './common';\r\nimport type { ConversationHistory } from './conversation-history';\r\nimport { systemPromptToTaskPlanning } from './prompt/llm-planning';\r\nimport { describeUserPage } from './prompt/util';\r\nimport { callAIWithObjectResponse } from './service-caller/index';\r\n\r\nconst debug = getDebug('planning');\r\n\r\nexport async function plan(\r\n  userInstruction: string,\r\n  opts: {\r\n    context: UIContext;\r\n    interfaceType: InterfaceType;\r\n    actionSpace: DeviceAction<any>[];\r\n    actionContext?: string;\r\n    modelConfig: IModelConfig;\r\n    conversationHistory?: ConversationHistory;\r\n  },\r\n): Promise<PlanningAIResponse> {\r\n  const { context, modelConfig, conversationHistory } = opts;\r\n  const { screenshotBase64, size } = context;\r\n\r\n  const { modelName, vlMode } = modelConfig;\r\n\r\n  const { description: pageDescription, elementById } = await describeUserPage(\r\n    context,\r\n    { vlMode },\r\n  );\r\n  const systemPrompt = await systemPromptToTaskPlanning({\r\n    actionSpace: opts.actionSpace,\r\n    vlMode: vlMode,\r\n  });\r\n\r\n  let imagePayload = screenshotBase64;\r\n  let imageWidth = size.width;\r\n  let imageHeight = size.height;\r\n  const rightLimit = imageWidth;\r\n  const bottomLimit = imageHeight;\r\n  if (vlMode === 'qwen-vl') {\r\n    const paddedResult = await paddingToMatchBlockByBase64(imagePayload);\r\n    imageWidth = paddedResult.width;\r\n    imageHeight = paddedResult.height;\r\n    imagePayload = paddedResult.imageBase64;\r\n  } else if (vlMode === 'qwen3-vl') {\r\n    // const paddedResult = await paddingToMatchBlockByBase64(imagePayload, 32);\r\n    // imageWidth = paddedResult.width;\r\n    // imageHeight = paddedResult.height;\r\n    // imagePayload = paddedResult.imageBase64;\r\n  } else if (!vlMode) {\r\n    imagePayload = await markupImageForLLM(screenshotBase64, context.tree, {\r\n      width: imageWidth,\r\n      height: imageHeight,\r\n    });\r\n  }\r\n\r\n  warnGPT4oSizeLimit(size, modelName);\r\n\r\n  const historyLog = opts.conversationHistory?.snapshot() || [];\r\n  // .filter((item) => item.role === 'assistant') || [];\r\n\r\n  const knowledgeContext: ChatCompletionMessageParam[] = opts.actionContext\r\n    ? [\r\n        {\r\n          role: 'user',\r\n          content: [\r\n            {\r\n              type: 'text',\r\n              text: `<high_priority_knowledge>${opts.actionContext}</high_priority_knowledge>`,\r\n            },\r\n          ],\r\n        },\r\n      ]\r\n    : [];\r\n\r\n  const instruction: ChatCompletionMessageParam[] = [\r\n    {\r\n      role: 'user',\r\n      content: [\r\n        {\r\n          type: 'text',\r\n          text: `<user_instruction>${userInstruction}</user_instruction>`,\r\n        },\r\n      ],\r\n    },\r\n  ];\r\n\r\n  const msgs: ChatCompletionMessageParam[] = [\r\n    { role: 'system', content: systemPrompt },\r\n    ...knowledgeContext,\r\n    ...instruction,\r\n    ...historyLog,\r\n    {\r\n      role: 'user',\r\n      content: [\r\n        {\r\n          type: 'image_url',\r\n          image_url: {\r\n            url: imagePayload,\r\n            detail: 'high',\r\n          },\r\n        },\r\n        ...(vlMode\r\n          ? []\r\n          : ([\r\n              {\r\n                type: 'text',\r\n                text: pageDescription,\r\n              },\r\n            ] as ChatCompletionContentPart[])),\r\n      ],\r\n    },\r\n  ];\r\n\r\n  const { content, usage } = await callAIWithObjectResponse<PlanningAIResponse>(\r\n    msgs,\r\n    AIActionType.PLAN,\r\n    modelConfig,\r\n  );\r\n  const rawResponse = JSON.stringify(content, undefined, 2);\r\n  const planFromAI = content;\r\n\r\n  const actions =\r\n    (planFromAI.action?.type ? [planFromAI.action] : planFromAI.actions) || [];\r\n  const returnValue: PlanningAIResponse = {\r\n    ...planFromAI,\r\n    actions,\r\n    rawResponse,\r\n    usage,\r\n    yamlFlow: buildYamlFlowFromPlans(\r\n      actions,\r\n      opts.actionSpace,\r\n      planFromAI.sleep,\r\n    ),\r\n  };\r\n\r\n  assert(planFromAI, \"can't get plans from AI\");\r\n\r\n  // TODO: use zod.parse to parse the action.param, and then fill the bbox param.\r\n  actions.forEach((action) => {\r\n    const type = action.type;\r\n    const actionInActionSpace = opts.actionSpace.find(\r\n      (action) => action.name === type,\r\n    );\r\n\r\n    debug('actionInActionSpace matched', actionInActionSpace);\r\n    const locateFields = actionInActionSpace\r\n      ? findAllMidsceneLocatorField(actionInActionSpace.paramSchema)\r\n      : [];\r\n\r\n    debug('locateFields', locateFields);\r\n\r\n    locateFields.forEach((field) => {\r\n      const locateResult = action.param[field];\r\n      if (locateResult) {\r\n        if (vlMode) {\r\n          action.param[field] = fillBboxParam(\r\n            locateResult,\r\n            imageWidth,\r\n            imageHeight,\r\n            rightLimit,\r\n            bottomLimit,\r\n            vlMode,\r\n          );\r\n        } else {\r\n          const element = elementById(locateResult);\r\n          if (element) {\r\n            action.param[field].id = element.id;\r\n          }\r\n        }\r\n      }\r\n    });\r\n  });\r\n  // in Qwen-VL, error means error. In GPT-4o, error may mean more actions are needed.\r\n  assert(!planFromAI.error, `Failed to plan actions: ${planFromAI.error}`);\r\n\r\n  if (\r\n    actions.length === 0 &&\r\n    returnValue.more_actions_needed_by_instruction &&\r\n    !returnValue.sleep\r\n  ) {\r\n    console.warn(\r\n      'No actions planned for the prompt, but model said more actions are needed:',\r\n      userInstruction,\r\n    );\r\n  }\r\n\r\n  conversationHistory?.append({\r\n    role: 'assistant',\r\n    content: [\r\n      {\r\n        type: 'text',\r\n        text: rawResponse,\r\n      },\r\n    ],\r\n  });\r\n  conversationHistory?.append({\r\n    role: 'user',\r\n    content: [\r\n      {\r\n        type: 'text',\r\n        text: 'I have finished the action previously planned',\r\n      },\r\n    ],\r\n  });\r\n\r\n  return returnValue;\r\n}\r\n"],"names":["__webpack_require__","definition","key","Object","obj","prop","Symbol","debug","getDebug","plan","userInstruction","opts","_opts_conversationHistory","_planFromAI_action","context","modelConfig","conversationHistory","screenshotBase64","size","modelName","vlMode","pageDescription","elementById","describeUserPage","systemPrompt","systemPromptToTaskPlanning","imagePayload","imageWidth","imageHeight","rightLimit","bottomLimit","paddedResult","paddingToMatchBlockByBase64","markupImageForLLM","warnGPT4oSizeLimit","historyLog","knowledgeContext","instruction","msgs","content","usage","callAIWithObjectResponse","AIActionType","rawResponse","JSON","undefined","planFromAI","actions","returnValue","buildYamlFlowFromPlans","assert","action","type","actionInActionSpace","locateFields","findAllMidsceneLocatorField","field","locateResult","fillBboxParam","element","console"],"mappings":";;;IAAAA,oBAAoB,CAAC,GAAG,CAAC,UAASC;QACjC,IAAI,IAAIC,OAAOD,WACR,IAAGD,oBAAoB,CAAC,CAACC,YAAYC,QAAQ,CAACF,oBAAoB,CAAC,CAAC,UAASE,MACzEC,OAAO,cAAc,CAAC,UAASD,KAAK;YAAE,YAAY;YAAM,KAAKD,UAAU,CAACC,IAAI;QAAC;IAGzF;;;ICNAF,oBAAoB,CAAC,GAAG,CAACI,KAAKC,OAAUF,OAAO,SAAS,CAAC,cAAc,CAAC,IAAI,CAACC,KAAKC;;;ICClFL,oBAAoB,CAAC,GAAG,CAAC;QACxB,IAAG,AAAkB,eAAlB,OAAOM,UAA0BA,OAAO,WAAW,EACrDH,OAAO,cAAc,CAAC,UAASG,OAAO,WAAW,EAAE;YAAE,OAAO;QAAS;QAEtEH,OAAO,cAAc,CAAC,UAAS,cAAc;YAAE,OAAO;QAAK;IAC5D;;;;;;;;;;;;;;ACqBA,MAAMI,QAAQC,AAAAA,IAAAA,uBAAAA,QAAAA,AAAAA,EAAS;AAEhB,eAAeC,KACpBC,eAAuB,EACvBC,IAOC;QAwCkBC,2BAiEhBC;IAvGH,MAAM,EAAEC,OAAO,EAAEC,WAAW,EAAEC,mBAAmB,EAAE,GAAGL;IACtD,MAAM,EAAEM,gBAAgB,EAAEC,IAAI,EAAE,GAAGJ;IAEnC,MAAM,EAAEK,SAAS,EAAEC,MAAM,EAAE,GAAGL;IAE9B,MAAM,EAAE,aAAaM,eAAe,EAAEC,WAAW,EAAE,GAAG,MAAMC,AAAAA,IAAAA,wBAAAA,gBAAAA,AAAAA,EAC1DT,SACA;QAAEM;IAAO;IAEX,MAAMI,eAAe,MAAMC,AAAAA,IAAAA,gCAAAA,0BAAAA,AAAAA,EAA2B;QACpD,aAAad,KAAK,WAAW;QAC7B,QAAQS;IACV;IAEA,IAAIM,eAAeT;IACnB,IAAIU,aAAaT,KAAK,KAAK;IAC3B,IAAIU,cAAcV,KAAK,MAAM;IAC7B,MAAMW,aAAaF;IACnB,MAAMG,cAAcF;IACpB,IAAIR,AAAW,cAAXA,QAAsB;QACxB,MAAMW,eAAe,MAAMC,AAAAA,IAAAA,oBAAAA,2BAAAA,AAAAA,EAA4BN;QACvDC,aAAaI,aAAa,KAAK;QAC/BH,cAAcG,aAAa,MAAM;QACjCL,eAAeK,aAAa,WAAW;IACzC,OAAO,IAAIX,AAAW,eAAXA;SAKJ,IAAI,CAACA,QACVM,eAAe,MAAMO,AAAAA,IAAAA,mCAAAA,iBAAAA,AAAAA,EAAkBhB,kBAAkBH,QAAQ,IAAI,EAAE;QACrE,OAAOa;QACP,QAAQC;IACV;IAGFM,IAAAA,mCAAAA,kBAAAA,AAAAA,EAAmBhB,MAAMC;IAEzB,MAAMgB,aAAavB,AAAAA,SAAAA,CAAAA,4BAAAA,KAAK,mBAAmB,AAAD,IAAvBA,KAAAA,IAAAA,0BAA0B,QAAQ,EAAC,KAAK,EAAE;IAG7D,MAAMwB,mBAAiDzB,KAAK,aAAa,GACrE;QACE;YACE,MAAM;YACN,SAAS;gBACP;oBACE,MAAM;oBACN,MAAM,CAAC,yBAAyB,EAAEA,KAAK,aAAa,CAAC,0BAA0B,CAAC;gBAClF;aACD;QACH;KACD,GACD,EAAE;IAEN,MAAM0B,cAA4C;QAChD;YACE,MAAM;YACN,SAAS;gBACP;oBACE,MAAM;oBACN,MAAM,CAAC,kBAAkB,EAAE3B,gBAAgB,mBAAmB,CAAC;gBACjE;aACD;QACH;KACD;IAED,MAAM4B,OAAqC;QACzC;YAAE,MAAM;YAAU,SAASd;QAAa;WACrCY;WACAC;WACAF;QACH;YACE,MAAM;YACN,SAAS;gBACP;oBACE,MAAM;oBACN,WAAW;wBACT,KAAKT;wBACL,QAAQ;oBACV;gBACF;mBACIN,SACA,EAAE,GACD;oBACC;wBACE,MAAM;wBACN,MAAMC;oBACR;iBACD;aACN;QACH;KACD;IAED,MAAM,EAAEkB,OAAO,EAAEC,KAAK,EAAE,GAAG,MAAMC,AAAAA,IAAAA,yBAAAA,wBAAAA,AAAAA,EAC/BH,MACAI,mCAAAA,YAAAA,CAAAA,IAAiB,EACjB3B;IAEF,MAAM4B,cAAcC,KAAK,SAAS,CAACL,SAASM,QAAW;IACvD,MAAMC,aAAaP;IAEnB,MAAMQ,UACHlC,AAAAA,CAAAA,SAAAA,CAAAA,qBAAAA,WAAW,MAAM,AAAD,IAAhBA,KAAAA,IAAAA,mBAAmB,IAAI,AAAD,IAAI;QAACiC,WAAW,MAAM;KAAC,GAAGA,WAAW,OAAM,KAAM,EAAE;IAC5E,MAAME,cAAkC;QACtC,GAAGF,UAAU;QACbC;QACAJ;QACAH;QACA,UAAUS,AAAAA,IAAAA,mCAAAA,sBAAAA,AAAAA,EACRF,SACApC,KAAK,WAAW,EAChBmC,WAAW,KAAK;IAEpB;IAEAI,IAAAA,sBAAAA,MAAAA,AAAAA,EAAOJ,YAAY;IAGnBC,QAAQ,OAAO,CAAC,CAACI;QACf,MAAMC,OAAOD,OAAO,IAAI;QACxB,MAAME,sBAAsB1C,KAAK,WAAW,CAAC,IAAI,CAC/C,CAACwC,SAAWA,OAAO,IAAI,KAAKC;QAG9B7C,MAAM,+BAA+B8C;QACrC,MAAMC,eAAeD,sBACjBE,AAAAA,IAAAA,mCAAAA,2BAAAA,AAAAA,EAA4BF,oBAAoB,WAAW,IAC3D,EAAE;QAEN9C,MAAM,gBAAgB+C;QAEtBA,aAAa,OAAO,CAAC,CAACE;YACpB,MAAMC,eAAeN,OAAO,KAAK,CAACK,MAAM;YACxC,IAAIC,cACF,IAAIrC,QACF+B,OAAO,KAAK,CAACK,MAAM,GAAGE,AAAAA,IAAAA,mCAAAA,aAAAA,AAAAA,EACpBD,cACA9B,YACAC,aACAC,YACAC,aACAV;iBAEG;gBACL,MAAMuC,UAAUrC,YAAYmC;gBAC5B,IAAIE,SACFR,OAAO,KAAK,CAACK,MAAM,CAAC,EAAE,GAAGG,QAAQ,EAAE;YAEvC;QAEJ;IACF;IAEAT,IAAAA,sBAAAA,MAAAA,AAAAA,EAAO,CAACJ,WAAW,KAAK,EAAE,CAAC,wBAAwB,EAAEA,WAAW,KAAK,EAAE;IAEvE,IACEC,AAAmB,MAAnBA,QAAQ,MAAM,IACdC,YAAY,kCAAkC,IAC9C,CAACA,YAAY,KAAK,EAElBY,QAAQ,IAAI,CACV,8EACAlD;IAIJM,QAAAA,uBAAAA,oBAAqB,MAAM,CAAC;QAC1B,MAAM;QACN,SAAS;YACP;gBACE,MAAM;gBACN,MAAM2B;YACR;SACD;IACH;IACA3B,QAAAA,uBAAAA,oBAAqB,MAAM,CAAC;QAC1B,MAAM;QACN,SAAS;YACP;gBACE,MAAM;gBACN,MAAM;YACR;SACD;IACH;IAEA,OAAOgC;AACT"}